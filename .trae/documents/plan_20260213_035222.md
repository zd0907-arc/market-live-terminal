# 解决 AI Summary 网络超时问题

"Test Connection" 成功但 "AI Summary" 失败，原因是请求耗时差异。AI 摘要生成通常需要 5-20 秒，而前端或网络环境的默认超时时间较短（可能为 10-30 秒），导致连接被提前切断。同时，前端错误处理逻辑存在漏洞，未能正确解析后端的业务错误码。

## 1. 修复前端错误处理 (Frontend)
当前端请求收到 HTTP 200 但业务状态码为 500 时，前端代码未抛出异常，导致错误被忽略，或者因连接被切断而直接报 "Network Error"。

*   **修改文件**: `src/components/sentiment/SentimentDashboard.tsx`
*   **优化内容**:
    *   在 `handleGenerateSummary` 中，显式检查后端返回的 `code`。
    *   如果 `code !== 200`，手动抛出错误，确保错误信息能被 `catch` 块捕获并显示给用户。

## 2. 增加超时容忍度 (Frontend)
虽然无法直接修改浏览器或代理的超时设置，但我们可以确保前端 Axios 请求本身不设过短的限制。后端 LLM 服务已经设置了 30s 超时，前端应该至少等待这么久。

*   **修改文件**: `src/services/sentimentService.ts`
*   **优化内容**:
    *   为 `generateSummary` 的 Axios 请求显式增加 `timeout: 60000` (60秒)，防止客户端过早断开。

## 3. 后端容错增强 (Backend)
确保后端在 LLM 超时时，不仅记录日志，还能尽快返回给前端，而不是让连接挂起直到被切断。

*   **修改文件**: `backend/app/services/llm_service.py`
*   **优化内容**:
    *   确认 `requests.post` 的 `timeout` 已被设置为 30 秒（之前已修改，无需再次修改，确认即可）。

## 4. 验证计划
1.  **超时测试**: 刷新页面，点击 AI 摘要，观察请求是否能持续等待超过 10 秒而不报错。
2.  **错误显示**: 如果依然失败，弹窗应显示具体的后端错误信息（如 "LLM API Error: ..."），而不是通用的 "Network Error"。
