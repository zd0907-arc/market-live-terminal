# 大模型 (LLM) 服务失败修复计划

针对您遇到的“配置了 AI 相关东西，大模型还是失败”的问题，根据日志和代码分析，主要原因是后端调用 LLM 接口时发生了超时或网络错误，且缺乏有效的错误反馈机制。

## 1. 后端：增强 LLM 服务健壮性
目前 LLM 服务超时时间仅为 10 秒，对于某些模型（如 DeepSeek 或复杂的 GPT-4）来说可能过短。同时缺乏代理支持。

*   **修改文件**: `backend/app/services/llm_service.py`
*   **优化内容**:
    1.  **延长超时时间**: 将默认超时从 10 秒增加到 **30 秒**。
    2.  **增加代理支持**: 从配置中读取 `http_proxy` / `https_proxy`（如果存在），传递给 `requests`。
    3.  **详细错误日志**: 在捕获异常时，打印出具体的响应内容（如 API Key 无效、余额不足等），而不仅仅是简单的网络错误。

## 2. 后端：优化 API 错误返回
目前 `/sentiment/summary/{symbol}` 接口在发生异常时直接返回 500 错误，前端只收到 `Network Error`，无法得知具体原因（如 Key 错误或超时）。

*   **修改文件**: `backend/app/routers/sentiment.py`
*   **优化内容**:
    *   在捕获 `llm_service.generate_sentiment_summary` 的异常后，不再直接抛出 500，而是返回一个带有错误信息的 200 响应（或者更友好的 4xx），例如：
        ```json
        {
            "code": 500,
            "message": "LLM 调用超时，请检查网络或稍后重试",
            "data": null
        }
        ```
    *   确保前端能展示这个错误消息，而不是直接红屏或无反应。

## 3. 前端：增强错误提示
前端目前仅在控制台打印错误，用户感知不强。

*   **修改文件**: `src/components/sentiment/SentimentDashboard.tsx`
*   **优化内容**:
    *   在 `handleGenerateSummary` 中，如果后端返回错误信息，通过 `alert` 或 Toast 明确告知用户具体原因（如“API Key 无效”、“请求超时”等）。
    *   增加加载状态的文字提示，如“AI 正在思考中 (预计 10-20秒)...”。

## 4. 验证计划
1.  **超时测试**: 配置一个不存在的 Base URL，验证是否在 30 秒后提示“连接超时”。
2.  **正常测试**: 配置正确的 Base URL 和 Key，验证是否能生成摘要。
